import json
from typing import Dict, List

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults

import config2
from safety_agent import safety_agent
from scenario_agent_with_verificator import scenario_agent_with_verificator

class ExternalResearchAgent:
    """
    Agent do zewnƒôtrznego researchu:
    - Tavily (internet),
    - GPT-4.1 (analiza),
    - perspektywa mieszka≈Ñca Atlantis,
    - WYMUSZONE WIARYGODNE LICZBY.
    """

    def __init__(self, max_results: int = 5, search_depth: str = "advanced"):

        # LLM
        self.llm = ChatOpenAI(
            model="gpt-4.1",
            api_key=lambda: config2.OPENAI_API_KEY,
            temperature=0.2,
            max_tokens=900,
        )

        # Tavily
        self.search_tool = TavilySearchResults(
            max_results=max_results,
            search_depth=search_depth,
        )

        # PROMPT Z WYMUSZENIEM LICZB
        self.research_prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                "T≈Çumaczysz sytuacjƒô geopolitycznƒÖ zwyk≈Çemu mieszka≈Ñcowi fikcyjnego pa≈Ñstwa Atlantis. "
                "Wyja≈õniasz, jak wydarzenia w innych krajach wp≈ÇywajƒÖ na jego ≈ºycie: ceny, pracƒô, "
                "bezpiecze≈Ñstwo i stabilno≈õƒá pa≈Ñstwa. "
                "NIE u≈ºywaj urzƒôdniczego jƒôzyka. Pisz prosto i konkretnie. "
                "WOLNO korzystaƒá TYLKO z danych zawartych w wynikach wyszukiwania i scenariuszu. "
                "NIE WOLNO wymy≈õlaƒá ≈ºadnych fakt√≥w ani liczb."
            ),
            (
                "user",
                "Pa≈Ñstwo, kt√≥rego jestem obywatelem: {home_country_name}\n\n"
                "Kontekst mojego pa≈Ñstwa (Atlantis):\n{home_context}\n\n"
                "Kraj, w kt√≥rym dzieje siƒô wa≈ºna sytuacja: {foreign_country}\n"
                "Temat: {subject}\n\n"
                "Scenariusz sytuacyjny:\n{scenario}\n\n"
                "Wyniki wyszukiwania (surowe dane):\n{search_results}\n\n"
                "Zadanie:\n"
                "- napisz OKO≈ÅO 6 ZDA≈É (5‚Äì7 zda≈Ñ),\n"
                "- co najmniej 4 zdania majƒÖ dotyczyƒá wp≈Çywu na ≈ºycie mieszka≈Ñc√≥w Atlantis,\n"
                "- maksymalnie 1 zdanie mo≈ºe opisywaƒá sam kraj {foreign_country},\n"
                "- wska≈º 1‚Äì2 najwiƒôksze zagro≈ºenia lub szanse,\n"
                "- je≈õli w danych wystƒôpujƒÖ JAKIEKOLWIEK LICZBY (kwoty, %, MW, eksport, import), "
                "MUSISZ przytoczyƒá co najmniej 1‚Äì2 takie liczby,\n"
                "- NIE WOLNO wymy≈õlaƒá liczb,\n"
                "- je≈õli w ≈∫r√≥d≈Çach NIE MA LICZB, musisz jasno napisaƒá: "
                "‚Äûw dostƒôpnych ≈∫r√≥d≈Çach nie podano konkretnych danych liczbowych‚Äù,\n"
                "- pisz po polsku, prostym jƒôzykiem."
            ),
        ])

    def analyze_impact(
        self,
        home_country_name: str,
        home_context: str,
        foreign_country: str,
        subject: str,
        scenario: str,
    ) -> str:

        query = (
            f"najnowsze informacje o temacie '{subject}' w kraju {foreign_country}, "
            f"lata 2024-2025, gospodarka, bezpiecze≈Ñstwo, handel, polityka"
        )

        # Tavily
        try:
            search_results = self.search_tool.invoke({"query": query})
        except Exception as e:
            print(f"‚ùå Tavily error: {e}")
            return "Nie uda≈Ço siƒô pobraƒá danych z internetu."

        print(f"\n=== [DEBUG] TAVILY: {foreign_country} | {subject} ===")
        try:
            print(json.dumps(search_results, indent=2, ensure_ascii=False))
        except Exception:
            print(search_results)

        # GPT
        messages = self.research_prompt.format_messages(
            home_country_name=home_country_name,
            home_context=home_context,
            foreign_country=foreign_country,
            subject=subject,
            scenario=scenario,
            search_results=search_results,
        )

        try:
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            print(f"‚ùå LLM error: {e}")
            return "Nie uda≈Ço siƒô wygenerowaƒá analizy."

    def analyze_matrix_for_scenario(
        self,
        home_country_name: str,
        home_context: str,
        scenario: str,
        foreign_countries: List[str],
        subjects: List[str],
    ) -> Dict[str, Dict[str, str]]:

        results: Dict[str, Dict[str, str]] = {}

        for country in foreign_countries:
            results[country] = {}

            print("\n" + "=" * 100)
            print(f"üåç ANALIZA DLA KRAJU: {country}")
            print("=" * 100)

            for subject in subjects:
                print("\n" + "#" * 80)
                print(f"### TEMAT: {subject}")
                print("#" * 80)

                summary = self.analyze_impact(
                    home_country_name=home_country_name,
                    home_context=home_context,
                    foreign_country=country,
                    subject=subject,
                    scenario=scenario,
                )

                results[country][subject] = summary

                print("\n--- ANALIZA (~6 zda≈Ñ, z liczbami je≈õli sƒÖ) ---")
                print(summary)

        return results